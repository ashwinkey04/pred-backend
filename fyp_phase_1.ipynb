{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/gist/ashwinkey04/de066da294792f198b7f74ad6ec702e8/fyp_phase_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqECZdj-apRi"
      },
      "source": [
        "# Phase 1\n",
        "\n",
        "> Gathering news articles and stock prices for a specific stock and preparing the dataset for sentiment analysis and stock value prediction\n",
        "\n",
        "\n",
        "#### How it works\n",
        "> This notebook fetches daily stock market data of a specified stock from [yfinance](https://www.yahoofinanceapi.com/) api and its daily news articles from [mediastack](https://mediastack.com/) api and creates a derived dataset which contains **news sentiment**. This notebook can be scheduled to run daily on Google Cloud Run to gather data daily\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiNDL2gCb5qk"
      },
      "source": [
        "\n",
        "#### Structure of dataset generated\n",
        "\n",
        "1. stock_history.csv\n",
        "2. news.json\n",
        "3. news_sentiment.csv\n",
        "\n",
        "#### stock_history.csv \n",
        "\n",
        "1. Date - Trading date\n",
        "2. Open - Open price of day\n",
        "3. High - Highest price of day\n",
        "4. Low - Lowest price of day\n",
        "5. Close - Closing price of day\n",
        "6. Volume - Amount of asset/security \n",
        "7. Dividends - Distribution of stock\n",
        "8. Stock splits - Shares of stock to its current shareholders\n",
        "\n",
        "\n",
        "#### news.json\n",
        "\n",
        "1. author - author of news article \n",
        "2. title - title of news article \n",
        "3. description - description of news article\n",
        "4. url - url of news article\n",
        "5. source - source of news article\n",
        "6. image - image of news article\n",
        "7. category - category of news article\n",
        "8. language - language of news article\n",
        "9. country - country name\n",
        "10. published_at - published date\n",
        "\n",
        "#### news_sentiment.csv\n",
        "\n",
        "1. published_at - published date\n",
        "2. title - title of news article \n",
        "3. description - description of news article\n",
        "4. url - url of news article\n",
        "5. sentiment - news sentiment\n",
        "6. sentiment_score - news sentiment score between 0 to 1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HCLQrst7k_bo"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: yfinance in /Users/ashwin/.conda/envs/jup/lib/python3.8/site-packages (0.1.74)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /Users/ashwin/.conda/envs/jup/lib/python3.8/site-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /Users/ashwin/.conda/envs/jup/lib/python3.8/site-packages (from yfinance) (1.3.4)\n",
            "Requirement already satisfied: lxml>=4.5.1 in /Users/ashwin/.conda/envs/jup/lib/python3.8/site-packages (from yfinance) (4.9.1)\n",
            "Requirement already satisfied: numpy>=1.15 in /Users/ashwin/.conda/envs/jup/lib/python3.8/site-packages (from yfinance) (1.21.4)\n",
            "Requirement already satisfied: requests>=2.26 in /Users/ashwin/.conda/envs/jup/lib/python3.8/site-packages (from yfinance) (2.26.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/ashwin/.conda/envs/jup/lib/python3.8/site-packages (from pandas>=0.24.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /Users/ashwin/.conda/envs/jup/lib/python3.8/site-packages (from pandas>=0.24.0->yfinance) (2021.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/ashwin/.conda/envs/jup/lib/python3.8/site-packages (from requests>=2.26->yfinance) (1.26.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/ashwin/.conda/envs/jup/lib/python3.8/site-packages (from requests>=2.26->yfinance) (2021.10.8)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/ashwin/.conda/envs/jup/lib/python3.8/site-packages (from requests>=2.26->yfinance) (2.0.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/ashwin/.conda/envs/jup/lib/python3.8/site-packages (from requests>=2.26->yfinance) (3.1)\n",
            "Requirement already satisfied: six>=1.5 in /Users/ashwin/.conda/envs/jup/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->yfinance) (1.15.0)\n",
            "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3.1 is available.\n",
            "You should consider upgrading via the '/Users/ashwin/.conda/envs/jup/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Install Yahoo Finance package\n",
        "!pip install yfinance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import other libraries \n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import os\n",
        "import json\n",
        "import datetime\n",
        "from datetime import date,timedelta\n",
        "import warnings\n",
        "import http.client, urllib.parse\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification,pipeline\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.max_rows', 500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# company symbol and name\n",
        "company_symbol=\"RELIANCE.NS\"\n",
        "\n",
        "#initialise today date\n",
        "today = str(date.today())\n",
        "yesterday = str(date.today()- timedelta(days = 1))\n",
        "\n",
        "# flag variables\n",
        "news_inserted=False\n",
        "\n",
        "#secret key of mediastack api\n",
        "mediastack_api_token = \"9f774391108184659c6eecd8dfdcd269\"\n",
        "\n",
        "# input file paths\n",
        "stock_history_file_path='../input/reliancestockandnewsdata/reliance_stock_history.csv'\n",
        "news_file_path='../input/reliancestockandnewsdata/reliance_news.json'\n",
        "news_sentiment_file_path='../input/reliancestockandnewsdata/reliance_news_sentiment.csv'\n",
        "\n",
        "# output file paths\n",
        "output_stock_history_file_path='./reliance_stock_history.csv'\n",
        "output_news_file_path='./reliance_news.json'\n",
        "output_news_sentiment_file_path='./reliance_news_sentiment.csv'\n",
        "\n",
        "# parameters for mediastack api\n",
        "search_query='reliance'\n",
        "conn = http.client.HTTPConnection('api.mediastack.com')\n",
        "params = urllib.parse.urlencode({\n",
        "    'keywords': search_query,\n",
        "    'access_key': mediastack_api_token,\n",
        "    'sort': 'published_desc',\n",
        "    'limit': 10,\n",
        "    'languages': 'en',\n",
        "    'country': 'in',\n",
        "    'date': yesterday\n",
        "    })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "ticker_object=yf.Ticker(company_symbol)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_stock_history_dataset():\n",
        "    reliance_stock_history=ticker_object.history(period=\"1y\").reset_index()\n",
        "    return reliance_stock_history\n",
        "\n",
        "def update_stock_history_dataset():\n",
        "    reliance_stock_history=pd.read_csv(stock_history_file_path)\n",
        "    reliance_stock_history.Date=pd.to_datetime(reliance_stock_history.Date, format='%Y/%m/%d')\n",
        "    today_reliance_stock_data=ticker_object.history(period=\"1d\")\n",
        "    today_reliance_stock_data=today_reliance_stock_data.reset_index()\n",
        "    last_stock_date=str(today_reliance_stock_data.loc[0,'Date']).split()[0]\n",
        "    if last_stock_date == reliance_stock_history['Date'].dt.strftime('%Y-%m-%d')[len(reliance_stock_history)-1]: #if already inserted \n",
        "        reliance_stock_history.iloc[-1:,:]=today_reliance_stock_data.iloc[-1].tolist()\n",
        "    else:\n",
        "        last_position=len(reliance_stock_history)\n",
        "        reliance_stock_history.loc[last_position]=today_reliance_stock_data.iloc[-1].tolist()\n",
        "    return reliance_stock_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create stock market history dataset\n",
        "ticker_object=yf.Ticker(company_symbol)\n",
        "if os.path.exists(stock_history_file_path)==False:\n",
        "    reliance_stock_history=create_stock_history_dataset()\n",
        "else:\n",
        "    reliance_stock_history=update_stock_history_dataset()\n",
        "\n",
        "\n",
        "reliance_stock_history.to_csv(output_stock_history_file_path,index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create news dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_news_dataset():\n",
        "    conn.request('GET', '/v1/news?{}'.format(params))\n",
        "    res = conn.getresponse().read()\n",
        "    reliance_news=json.loads(res.decode('utf-8'))[\"data\"]\n",
        "    return reliance_news\n",
        "\n",
        "def update_news_dataset():\n",
        "    global news_inserted\n",
        "    with open(news_file_path,'r') as file:\n",
        "        reliance_news=json.load(file)\n",
        "        for news in reliance_news['articles']:\n",
        "            if news['published_at'].split('T')[0]==yesterday:\n",
        "                news_inserted=True\n",
        "                break\n",
        "        current_reliance_news=None\n",
        "        if news_inserted==False:\n",
        "            conn.request('GET', '/v1/news?{}'.format(params))\n",
        "            res = conn.getresponse().read()\n",
        "            current_reliance_news=json.loads(res.decode('utf-8'))[\"data\"]\n",
        "            reliance_news['articles']+=current_reliance_news\n",
        "        return reliance_news['articles'],current_reliance_news"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "#create news dataset \n",
        "if os.path.exists(news_file_path)==False:\n",
        "    reliance_news=create_news_dataset()\n",
        "    current_reliance_news=reliance_news.copy()\n",
        "else:\n",
        "    reliance_news,current_reliance_news=update_news_dataset()\n",
        "\n",
        "with open(output_news_file_path,'w') as file:\n",
        "    json.dump({\"articles\":reliance_news},file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Predict sentiment on articles\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: 100%|██████████| 252/252 [00:00<00:00, 72.7kB/s]\n",
            "Downloading: 100%|██████████| 758/758 [00:00<00:00, 326kB/s]\n",
            "Downloading: 100%|██████████| 226k/226k [00:00<00:00, 238kB/s]  \n",
            "Downloading: 100%|██████████| 112/112 [00:00<00:00, 50.5kB/s]\n",
            "Downloading:   9%|▉         | 38.8M/418M [00:54<13:36, 487kB/s]   "
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\")\n",
        "classifier = pipeline('sentiment-analysis', model=model, tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_news_sentiment_dataset(news_sentiments):\n",
        "    last_position=len(news_sentiments)\n",
        "    article_ind=last_position\n",
        "    title_description=[]\n",
        "    if current_reliance_news!=None:\n",
        "        for article in current_reliance_news:\n",
        "            title_description.append(article['title']+' '+article['description'])\n",
        "            news_sentiments.at[article_ind,'published_at']=article['published_at']\n",
        "            news_sentiments.at[article_ind,'title']=article['title']\n",
        "            news_sentiments.at[article_ind,'description']=article['description']\n",
        "            news_sentiments.at[article_ind,'url']=article['url']\n",
        "            article_ind+=1\n",
        "        news_label_and_scores=classifier(list(title_description))\n",
        "        labels=[pred['label'] for pred in news_label_and_scores]\n",
        "        scores=[pred['score'] for pred in news_label_and_scores]\n",
        "        news_sentiments.at[last_position:,'sentiment']=labels\n",
        "        news_sentiments.at[last_position:,'sentiment_score']=scores\n",
        "    \n",
        "    news_sentiments.to_csv(output_news_sentiment_file_path,index=None)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Add news sentiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "news_sentiments=None\n",
        "if os.path.exists(news_sentiment_file_path):\n",
        "    news_sentiments=pd.read_csv(news_sentiment_file_path,index_col=None)                     \n",
        "else:\n",
        "    news_sentiments=pd.DataFrame(columns=['published_at','title','description','url','sentiment','sentiment_score'])\n",
        "create_news_sentiment_dataset(news_sentiments)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyO0dZvZwzR/FaKLDlaFU2Yw",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.6 ('jup')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "03d522a7aaf957b32e1f3c35d698e3d655ebc6e421de856c2141e007302a70db"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
